# ğŸš• Python Project - NYC Taxi Data Pipeline

> Un projet Python complet de Data Engineering pour tÃ©lÃ©charger, transformer et charger les donnÃ©es de taxis NYC dans PostgreSQL.

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](https://www.python.org/)
[![uv](https://img.shields.io/badge/uv-Package_Manager-green)](https://github.com/astral-sh/uv)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue?logo=postgresql)](https://www.postgresql.org/)
[![Polars](https://img.shields.io/badge/Polars-DataFrame-orange)](https://www.pola.rs/)

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [PrÃ©requis](#-prÃ©requis)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Modules](#-modules)
- [Configuration](#-configuration)
- [Bonnes Pratiques](#-bonnes-pratiques)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **pipeline ETL complet** pour gÃ©rer les donnÃ©es publiques des taxis jaunes de New York City (NYC Yellow Taxi Trip Records). Il illustre les bonnes pratiques de Data Engineering en Python.

### FonctionnalitÃ©s

- âœ… **TÃ©lÃ©chargement automatisÃ©** : RÃ©cupÃ©ration des donnÃ©es mensuelles depuis AWS S3
- âœ… **Gestion incrÃ©mentale** : TÃ©lÃ©chargement uniquement des fichiers manquants
- âœ… **Transformation de donnÃ©es** : Utilisation de Polars pour des transformations rapides
- âœ… **Chargement PostgreSQL** : Ingestion automatique dans une base de donnÃ©es
- âœ… **Logging structurÃ©** : TraÃ§abilitÃ© complÃ¨te de toutes les opÃ©rations
- âœ… **Gestion d'erreurs** : Robustesse face aux problÃ¨mes rÃ©seau et de donnÃ©es

---

## ğŸ—ï¸ Architecture

Le projet suit une architecture modulaire classique en Data Engineering :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS S3        â”‚  DonnÃ©es sources (Parquet)
â”‚   (NYC Open     â”‚
â”‚    Data)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ download.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Local Storage  â”‚  Stockage temporaire
â”‚  ./data/        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ save.py
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚  Base de donnÃ©es cible
â”‚  (workshop)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de donnÃ©es

1. **Download** : TÃ©lÃ©chargement des fichiers Parquet depuis AWS
2. **Storage** : Sauvegarde locale dans `./data/yellow_tripdata/`
3. **Schema Generation** : DÃ©tection automatique du schÃ©ma avec Polars
4. **Database Creation** : CrÃ©ation des tables PostgreSQL
5. **Data Loading** : Chargement par batch dans PostgreSQL

---

## ğŸ“‹ PrÃ©requis

- **Python** 3.10 ou supÃ©rieur
- **uv** - Gestionnaire de packages rapide ([Installation](https://github.com/astral-sh/uv))
- **PostgreSQL** 15+ avec base de donnÃ©es accessible
- **Docker** (optionnel) - Pour lancer PostgreSQL localement

### VÃ©rifier les prÃ©requis

```bash
# Python version
python --version  # >= 3.10

# uv installÃ©
uv --version

# PostgreSQL accessible
psql --version
```

---

## âš¡ Installation

### 1. Cloner le repository

```bash
git clone https://github.com/IFRI-Future-of-AI/Data-Eng-Workshop.git
cd Data-Eng-Workshop/python_project
```

### 2. Configurer l'environnement

CrÃ©er un fichier `.env` avec vos identifiants PostgreSQL :

```bash
POSTGRESQL_HOST=localhost
POSTGRESQL_PORT=5432
POSTGRESQL_DATABASE=workshop
POSTGRESQL_USER=postgres
POSTGRESQL_PASSWORD=postgres
```

> **Note** : Le fichier `.env` est dÃ©jÃ  prÃ©sent avec des valeurs par dÃ©faut.

### 3. Installer les dÃ©pendances

Avec **uv** (recommandÃ©) :

```bash
# CrÃ©er un environnement virtuel et installer les dÃ©pendances
uv venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
uv pip install -e .
```

Avec **pip** (alternative) :

```bash
pip install -r pyproject.toml
```

### 4. Lancer PostgreSQL (si nÃ©cessaire)

Si vous n'avez pas PostgreSQL installÃ©, utilisez Docker :

```bash
# Depuis la racine du projet
cd ..
docker compose up -d
```

---

## ğŸš€ Utilisation

### ExÃ©cution du pipeline complet

```bash
python main.py
```

### Workflow dÃ©taillÃ©

Le script `main.py` exÃ©cute automatiquement :

1. **TÃ©lÃ©chargement des zones de taxi** (`download_taxi_zones()`)
2. **TÃ©lÃ©chargement des donnÃ©es mensuelles** (`download_data_month_to_month()`)
   - PÃ©riode : Novembre 2023 Ã  Octobre 2025
   - Format : Parquet
3. **Chargement dans PostgreSQL** (`save_all_files_in_folder_in_postgresql_database()`)

### Utilisation personnalisÃ©e

Vous pouvez modifier `main.py` pour ajuster la pÃ©riode de tÃ©lÃ©chargement :

```python
from src import (
    download_data_month_to_month, 
    save_all_files_in_folder_in_postgresql_database,
    download_taxi_zones
)

def main():
    # TÃ©lÃ©charger les zones de taxi
    download_taxi_zones()
    
    # TÃ©lÃ©charger une pÃ©riode personnalisÃ©e
    download_data_month_to_month(
        start_month='2024-01',  # Janvier 2024
        end_month='2024-12'     # DÃ©cembre 2024
    )
    
    # Charger dans PostgreSQL
    save_all_files_in_folder_in_postgresql_database()

if __name__ == "__main__":
    main()
```

---

## ğŸ“Š Structure du Projet

```
python_project/
â”œâ”€â”€ data/                    # DonnÃ©es tÃ©lÃ©chargÃ©es (ignorÃ© par Git)
â”‚   â””â”€â”€ yellow_tripdata/     # Fichiers Parquet mensuels
â”œâ”€â”€ logs/                    # Logs structurÃ©s (ignorÃ© par Git)
â”‚   â”œâ”€â”€ download.log
â”‚   â”œâ”€â”€ database.log
â”‚   â””â”€â”€ save.log
â”œâ”€â”€ src/                     # Code source (package Python)
â”‚   â”œâ”€â”€ __init__.py          # Initialisation du package
â”‚   â”œâ”€â”€ constants.py         # Constantes et configuration
â”‚   â”œâ”€â”€ database.py          # Connexion et gestion PostgreSQL
â”‚   â”œâ”€â”€ download.py          # TÃ©lÃ©chargement des donnÃ©es
â”‚   â”œâ”€â”€ logger.py            # Configuration du logging
â”‚   â”œâ”€â”€ save.py              # Sauvegarde dans PostgreSQL
â”‚   â”œâ”€â”€ transform.py         # Transformations de donnÃ©es
â”‚   â””â”€â”€ visualize.py         # Visualisations (Plotly)
â”œâ”€â”€ .env                     # Variables d'environnement (ne pas committer)
â”œâ”€â”€ .gitignore               # Fichiers ignorÃ©s par Git
â”œâ”€â”€ .python-version          # Version Python (pour pyenv/uv)
â”œâ”€â”€ main.py                  # Point d'entrÃ©e principal
â”œâ”€â”€ pyproject.toml           # Configuration du projet et dÃ©pendances
â”œâ”€â”€ uv.lock                  # Lockfile des dÃ©pendances
â””â”€â”€ README.md                # Ce fichier
```

---

## ğŸ§© Modules

### 1. `constants.py` - Configuration centralisÃ©e

```python
# URLs et chemins
NYC_TRIPS_URL = "https://d37ci6vzurychx.cloudfront.net/trip-data/..."
TAXI_ZONE_URL = "https://d37ci6vzurychx.cloudfront.net/misc/..."
DATABASE_NAME = "workshop"

# Mapping de types pour PostgreSQL
SCHEMA_MAPPING = {
    'String': 'VARCHAR',
    'Int64': 'BIGINT',
    'Float64': 'DOUBLE PRECISION',
    'Datetime': 'TIMESTAMP',
}
```

### 2. `logger.py` - Logging structurÃ©

Fournit une fonction de configuration du logging :

```python
logger = configure_logging(
    log_file="download.log",
    logger_name="download"
)
```

**CaractÃ©ristiques** :
- Logs dans fichier + console
- Format standardisÃ© avec timestamp
- SÃ©paration par module

### 3. `download.py` - TÃ©lÃ©chargement de donnÃ©es

**Fonctions principales** :

- `download_taxi_zones()` : TÃ©lÃ©charge le fichier de rÃ©fÃ©rence des zones
- `download_data_month_to_month()` : TÃ©lÃ©chargement par plage de dates
- `download_data_for_month()` : TÃ©lÃ©chargement d'un mois spÃ©cifique
- `verify_if_file_already_downloaded()` : Ã‰vite les tÃ©lÃ©chargements redondants

**Exemple** :

```python
from src.download import download_data_month_to_month

# TÃ©lÃ©charger 6 mois de donnÃ©es
download_data_month_to_month(
    start_month='2024-01',
    end_month='2024-06'
)
```

### 4. `database.py` - Gestion PostgreSQL

**Fonctions principales** :

- `connect_to_postgresql_database()` : Connexion Ã  PostgreSQL
- `create_database_in_postgresql_database()` : CrÃ©ation de base de donnÃ©es

**Exemple** :

```python
from src.database import connect_to_postgresql_database

conn = connect_to_postgresql_database(database_name="workshop")
# Utiliser la connexion...
conn.close()
```

### 5. `save.py` - Chargement dans PostgreSQL

**Fonctions principales** :

- `generate_file_schema_for_postgresql_database()` : DÃ©tection automatique du schÃ©ma
- `create_table_in_postgresql_database()` : CrÃ©ation de tables
- `save_file_in_postgresql_database()` : Chargement d'un fichier
- `save_all_files_in_folder_in_postgresql_database()` : Chargement batch

**Workflow** :

1. Scan du dossier `./data/yellow_tripdata/`
2. Pour chaque fichier Parquet :
   - GÃ©nÃ©ration du schÃ©ma PostgreSQL
   - CrÃ©ation de la table (avec `DROP IF EXISTS`)
   - Chargement des donnÃ©es (100 premiÃ¨res lignes pour demo)

### 6. `transform.py` - Transformations

Module pour les transformations de donnÃ©es avec Polars.

### 7. `visualize.py` - Visualisations

Module pour crÃ©er des visualisations avec Plotly.

---

## âš™ï¸ Configuration

### Variables d'environnement (.env)

| Variable | Description | Valeur par dÃ©faut |
|----------|-------------|-------------------|
| `POSTGRESQL_HOST` | HÃ´te PostgreSQL | `localhost` |
| `POSTGRESQL_PORT` | Port PostgreSQL | `5432` |
| `POSTGRESQL_DATABASE` | Base de donnÃ©es par dÃ©faut | `workshop` |
| `POSTGRESQL_USER` | Utilisateur PostgreSQL | `postgres` |
| `POSTGRESQL_PASSWORD` | Mot de passe PostgreSQL | `postgres` |

### Personnaliser les constantes

Ã‰ditez `src/constants.py` pour modifier :

- URLs de tÃ©lÃ©chargement
- Dossiers de stockage
- Mapping de types SQL

---

## ğŸ“ Bonnes Pratiques ImplÃ©mentÃ©es

Ce projet illustre plusieurs bonnes pratiques de Data Engineering :

### 1. **Architecture modulaire**
- âœ… SÃ©paration claire des responsabilitÃ©s (download, database, save)
- âœ… Code rÃ©utilisable dans le package `src/`
- âœ… Point d'entrÃ©e unique (`main.py`)

### 2. **Gestion de configuration**
- âœ… Variables d'environnement avec `.env`
- âœ… Constantes centralisÃ©es dans `constants.py`
- âœ… Fichier `.env` non versionnÃ© (dans `.gitignore`)

### 3. **Logging et observabilitÃ©**
- âœ… Logging structurÃ© par module
- âœ… Logs dans fichier ET console
- âœ… Niveaux de log appropriÃ©s (INFO, ERROR, WARNING)

### 4. **Robustesse**
- âœ… Gestion des erreurs avec try/except
- âœ… VÃ©rification de l'existence des fichiers
- âœ… Validation des statuts HTTP
- âœ… CrÃ©ation automatique des dossiers

### 5. **Performance**
- âœ… Utilisation de Polars (plus rapide que Pandas)
- âœ… Format Parquet (compression efficace)
- âœ… TÃ©lÃ©chargement incrÃ©mental
- âœ… Chargement par batch

### 6. **Documentation**
- âœ… Docstrings sur toutes les fonctions
- âœ… Type hints (typing)
- âœ… README complet
- âœ… Commentaires sur le code complexe

### 7. **Gestion de dÃ©pendances**
- âœ… Utilisation de `uv` (moderne et rapide)
- âœ… Fichier `pyproject.toml` (standard Python moderne)
- âœ… Lockfile `uv.lock` pour reproductibilitÃ©

### 8. **Version control**
- âœ… `.gitignore` adaptÃ© (donnÃ©es, logs, venv)
- âœ… Fichiers sensibles exclus (`.env`)
- âœ… Structure de projet propre

---

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : Erreur de connexion PostgreSQL

```bash
# VÃ©rifier que PostgreSQL est lancÃ©
docker compose ps

# Tester la connexion manuellement
psql -h localhost -U postgres -d workshop
```

### ProblÃ¨me : TÃ©lÃ©chargement Ã©choue (403)

Certains mois peuvent ne pas Ãªtre disponibles sur AWS. Le script log les erreurs et continue.

### ProblÃ¨me : Table dÃ©jÃ  existante

Les tables sont automatiquement recrÃ©Ã©es (DROP IF EXISTS) pour Ã©viter les conflits.

### ProblÃ¨me : Logs trop verbeux

Modifiez le niveau de log dans `logger.py` :

```python
logger = configure_logging(
    log_file="download.log",
    log_level=logging.WARNING  # Au lieu de INFO
)
```

---

## ğŸ“š Ressources

### Documentation Python
- [Polars Documentation](https://pola-rs.github.io/polars-book/) - DataFrame rapide
- [psycopg2 Guide](https://www.psycopg.org/docs/) - PostgreSQL pour Python
- [SQLAlchemy Docs](https://docs.sqlalchemy.org/) - ORM et connexions DB
- [python-dotenv](https://pypi.org/project/python-dotenv/) - Gestion des .env

### Outils
- [uv Package Manager](https://github.com/astral-sh/uv) - Gestionnaire Python moderne
- [Docker PostgreSQL](https://hub.docker.com/_/postgres) - Image officielle

### Dataset
- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) - DonnÃ©es officielles
- [Data Dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf) - Description des colonnes

---

## ğŸ‘¤ Auteur

**Abraham KOLOBOE** - *Data Engineer & Formateur*

- GitHub: [@abrahamkoloboe27](https://github.com/abrahamkoloboe27)
- LinkedIn: [Abraham KOLOBOE](https://www.linkedin.com/in/abraham-zacharie-koloboe-data-science-ia-generative-llms-machine-learning/)
- Organisation: [IFRI Future of AI](https://github.com/IFRI-Future-of-AI)

---

## ğŸ“œ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](../LICENSE) pour plus de dÃ©tails.

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Pushez sur la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

---

<div align="center">
  
**CrÃ©Ã© dans le cadre du Data Engineering Workshop - IFRI Future of AI** ğŸ“

[â¬† Retour au Projet Principal](../README.md)

</div>
