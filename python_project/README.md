# üöï Python Project - NYC Taxi Data Pipeline

> Un projet Python complet de Data Engineering pour t√©l√©charger, transformer et charger les donn√©es de taxis NYC dans PostgreSQL.

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](https://www.python.org/)
[![uv](https://img.shields.io/badge/uv-Package_Manager-green)](https://github.com/astral-sh/uv)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue?logo=postgresql)](https://www.postgresql.org/)
[![Polars](https://img.shields.io/badge/Polars-DataFrame-orange)](https://www.pola.rs/)

## üìã Table des Mati√®res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [Pr√©requis](#-pr√©requis)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Modules](#-modules)
- [Configuration](#-configuration)
- [Bonnes Pratiques](#-bonnes-pratiques)

---

## üéØ Vue d'ensemble

Ce projet impl√©mente un **pipeline ETL complet** pour g√©rer les donn√©es publiques des taxis jaunes de New York City (NYC Yellow Taxi Trip Records). Il illustre les bonnes pratiques de Data Engineering en Python.

### Fonctionnalit√©s

- ‚úÖ **T√©l√©chargement automatis√©** : R√©cup√©ration des donn√©es mensuelles depuis AWS S3
- ‚úÖ **Gestion incr√©mentale** : T√©l√©chargement uniquement des fichiers manquants
- ‚úÖ **Transformation de donn√©es** : Utilisation de Polars pour des transformations rapides
- ‚úÖ **Chargement PostgreSQL** : Ingestion automatique dans une base de donn√©es
- ‚úÖ **Logging structur√©** : Tra√ßabilit√© compl√®te de toutes les op√©rations
- ‚úÖ **Gestion d'erreurs** : Robustesse face aux probl√®mes r√©seau et de donn√©es

---

## üèóÔ∏è Architecture

Le projet suit une architecture modulaire classique en Data Engineering :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AWS S3        ‚îÇ  Donn√©es sources (Parquet)
‚îÇ   (NYC Open     ‚îÇ
‚îÇ    Data)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ download.py
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Local Storage  ‚îÇ  Stockage temporaire
‚îÇ  ./data/        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ save.py
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL     ‚îÇ  Base de donn√©es cible
‚îÇ  (workshop)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux de donn√©es

1. **Download** : T√©l√©chargement des fichiers Parquet depuis AWS
2. **Storage** : Sauvegarde locale dans `./data/yellow_tripdata/`
3. **Schema Generation** : D√©tection automatique du sch√©ma avec Polars
4. **Database Creation** : Cr√©ation des tables PostgreSQL
5. **Data Loading** : Chargement par batch dans PostgreSQL

---

## üìã Pr√©requis

- **Python** 3.10 ou sup√©rieur
- **uv** - Gestionnaire de packages rapide ([Installation](https://github.com/astral-sh/uv))
- **PostgreSQL** 15+ avec base de donn√©es accessible
- **Docker** (optionnel) - Pour lancer PostgreSQL localement

### V√©rifier les pr√©requis

```bash
# Python version
python --version  # >= 3.10

# uv install√©
uv --version

# PostgreSQL accessible
psql --version
```

---

## ‚ö° Installation

### 1. Cloner le repository

```bash
git clone https://github.com/IFRI-Future-of-AI/Data-Eng-Workshop.git
cd Data-Eng-Workshop/python_project
```

### 2. Configurer l'environnement

Cr√©er un fichier `.env` avec vos identifiants PostgreSQL :

```bash
POSTGRESQL_HOST=localhost
POSTGRESQL_PORT=5432
POSTGRESQL_DATABASE=workshop
POSTGRESQL_USER=postgres
POSTGRESQL_PASSWORD=postgres
```

> **Note** : Le fichier `.env` est d√©j√† pr√©sent avec des valeurs par d√©faut.

### 3. Installer les d√©pendances

Avec **uv** (recommand√©) :

```bash
# Cr√©er un environnement virtuel et installer les d√©pendances
uv venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Installer les d√©pendances
uv pip install -e .
```

Avec **pip** (alternative) :

```bash
pip install -e .
```

### 4. Lancer PostgreSQL (si n√©cessaire)

Si vous n'avez pas PostgreSQL install√©, utilisez Docker :

```bash
# Depuis la racine du projet
cd ..
docker compose up -d
```

---

## üöÄ Utilisation

### Ex√©cution du pipeline complet

```bash
python main.py
```

### Workflow d√©taill√©

Le script `main.py` ex√©cute automatiquement :

1. **T√©l√©chargement des zones de taxi** (`download_taxi_zones()`)
2. **T√©l√©chargement des donn√©es mensuelles** (`download_data_month_to_month()`)
   - P√©riode : Novembre 2023 √† Octobre 2025
   - Format : Parquet
3. **Chargement dans PostgreSQL** (`save_all_files_in_folder_in_postgresql_database()`)

### Utilisation personnalis√©e

Vous pouvez modifier `main.py` pour ajuster la p√©riode de t√©l√©chargement :

```python
from src import (
    download_data_month_to_month, 
    save_all_files_in_folder_in_postgresql_database,
    download_taxi_zones
)

def main():
    # T√©l√©charger les zones de taxi
    download_taxi_zones()
    
    # T√©l√©charger une p√©riode personnalis√©e
    download_data_month_to_month(
        start_month='2024-01',  # Janvier 2024
        end_month='2024-12'     # D√©cembre 2024
    )
    
    # Charger dans PostgreSQL
    save_all_files_in_folder_in_postgresql_database()

if __name__ == "__main__":
    main()
```

---

## üìä Structure du Projet

```
python_project/
‚îú‚îÄ‚îÄ data/                    # Donn√©es t√©l√©charg√©es (ignor√© par Git)
‚îÇ   ‚îî‚îÄ‚îÄ yellow_tripdata/     # Fichiers Parquet mensuels
‚îú‚îÄ‚îÄ logs/                    # Logs structur√©s (ignor√© par Git)
‚îÇ   ‚îú‚îÄ‚îÄ download.log
‚îÇ   ‚îú‚îÄ‚îÄ database.log
‚îÇ   ‚îî‚îÄ‚îÄ save.log
‚îú‚îÄ‚îÄ src/                     # Code source (package Python)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Initialisation du package
‚îÇ   ‚îú‚îÄ‚îÄ constants.py         # Constantes et configuration
‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Connexion et gestion PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ download.py          # T√©l√©chargement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ logger.py            # Configuration du logging
‚îÇ   ‚îú‚îÄ‚îÄ save.py              # Sauvegarde dans PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ transform.py         # Transformations de donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ visualize.py         # Visualisations (Plotly)
‚îú‚îÄ‚îÄ .env                     # Variables d'environnement (ne pas committer)
‚îú‚îÄ‚îÄ .gitignore               # Fichiers ignor√©s par Git
‚îú‚îÄ‚îÄ .python-version          # Version Python (pour pyenv/uv)
‚îú‚îÄ‚îÄ main.py                  # Point d'entr√©e principal
‚îú‚îÄ‚îÄ pyproject.toml           # Configuration du projet et d√©pendances
‚îú‚îÄ‚îÄ uv.lock                  # Lockfile des d√©pendances
‚îî‚îÄ‚îÄ README.md                # Ce fichier
```

---

## üß© Modules

### 1. `constants.py` - Configuration centralis√©e

```python
# URLs et chemins
NYC_TRIPS_URL = "https://d37ci6vzurychx.cloudfront.net/trip-data/..."
TAXI_ZONE_URL = "https://d37ci6vzurychx.cloudfront.net/misc/..."
DATASET_FOLDER = 'yellow_tripdata'
DATABASE_NAME = "workshop"

# Mapping de types pour PostgreSQL
SCHEMA_MAPPING = {
    'String': 'VARCHAR',
    'Int64': 'BIGINT',
    'Float64': 'DOUBLE PRECISION',
    'Datetime': 'TIMESTAMP',
}
```

### 2. `logger.py` - Logging structur√©

Fournit une fonction de configuration du logging :

```python
logger = configure_logging(
    log_file="download.log",
    logger_name="download"
)
```

**Caract√©ristiques** :
- Logs dans fichier + console
- Format standardis√© avec timestamp
- S√©paration par module

### 3. `download.py` - T√©l√©chargement de donn√©es

**Fonctions principales** :

- `download_taxi_zones()` : T√©l√©charge le fichier de r√©f√©rence des zones
- `download_data_month_to_month()` : T√©l√©chargement par plage de dates
- `download_data_for_month()` : T√©l√©chargement d'un mois sp√©cifique
- `verify_if_file_already_downloaded()` : √âvite les t√©l√©chargements redondants

**Exemple** :

```python
from src.download import download_data_month_to_month

# T√©l√©charger 6 mois de donn√©es
download_data_month_to_month(
    start_month='2024-01',
    end_month='2024-06'
)
```

### 4. `database.py` - Gestion PostgreSQL

**Fonctions principales** :

- `connect_to_postgresql_database()` : Connexion √† PostgreSQL
- `create_database_in_postgresql_database()` : Cr√©ation de base de donn√©es

**Exemple** :

```python
from src.database import connect_to_postgresql_database

conn = connect_to_postgresql_database(database_name="workshop")
# Utiliser la connexion...
conn.close()
```

### 5. `save.py` - Chargement dans PostgreSQL

**Fonctions principales** :

- `generate_file_schema_for_postgresql_database()` : D√©tection automatique du sch√©ma
- `create_table_in_postgresql_database()` : Cr√©ation de tables
- `save_file_in_postgresql_database()` : Chargement d'un fichier
- `save_all_files_in_folder_in_postgresql_database()` : Chargement batch

**Workflow** :

1. Scan du dossier `./data/yellow_tripdata/`
2. Pour chaque fichier Parquet :
   - G√©n√©ration du sch√©ma PostgreSQL
   - Cr√©ation de la table (avec `DROP IF EXISTS`)
   - Chargement des donn√©es (100 premi√®res lignes pour demo)

### 6. `transform.py` - Transformations

Module pour les transformations de donn√©es avec Polars.

### 7. `visualize.py` - Visualisations

Module pour cr√©er des visualisations avec Plotly.

---

## ‚öôÔ∏è Configuration

### Variables d'environnement (.env)

| Variable | Description | Valeur par d√©faut |
|----------|-------------|-------------------|
| `POSTGRESQL_HOST` | H√¥te PostgreSQL | `localhost` |
| `POSTGRESQL_PORT` | Port PostgreSQL | `5432` |
| `POSTGRESQL_DATABASE` | Base de donn√©es par d√©faut | `workshop` |
| `POSTGRESQL_USER` | Utilisateur PostgreSQL | `postgres` |
| `POSTGRESQL_PASSWORD` | Mot de passe PostgreSQL | `postgres` |

### Personnaliser les constantes

√âditez `src/constants.py` pour modifier :

- URLs de t√©l√©chargement
- Dossiers de stockage
- Mapping de types SQL

---

## üéì Bonnes Pratiques Impl√©ment√©es

Ce projet illustre plusieurs bonnes pratiques de Data Engineering :

### 1. **Architecture modulaire**
- ‚úÖ S√©paration claire des responsabilit√©s (download, database, save)
- ‚úÖ Code r√©utilisable dans le package `src/`
- ‚úÖ Point d'entr√©e unique (`main.py`)

### 2. **Gestion de configuration**
- ‚úÖ Variables d'environnement avec `.env`
- ‚úÖ Constantes centralis√©es dans `constants.py`
- ‚úÖ Fichier `.env` non versionn√© (dans `.gitignore`)

### 3. **Logging et observabilit√©**
- ‚úÖ Logging structur√© par module
- ‚úÖ Logs dans fichier ET console
- ‚úÖ Niveaux de log appropri√©s (INFO, ERROR, WARNING)

### 4. **Robustesse**
- ‚úÖ Gestion des erreurs avec try/except
- ‚úÖ V√©rification de l'existence des fichiers
- ‚úÖ Validation des statuts HTTP
- ‚úÖ Cr√©ation automatique des dossiers

### 5. **Performance**
- ‚úÖ Utilisation de Polars (plus rapide que Pandas)
- ‚úÖ Format Parquet (compression efficace)
- ‚úÖ T√©l√©chargement incr√©mental
- ‚úÖ Chargement par batch

### 6. **Documentation**
- ‚úÖ Docstrings sur toutes les fonctions
- ‚úÖ Type hints (typing)
- ‚úÖ README complet
- ‚úÖ Commentaires sur le code complexe

### 7. **Gestion de d√©pendances**
- ‚úÖ Utilisation de `uv` (moderne et rapide)
- ‚úÖ Fichier `pyproject.toml` (standard Python moderne)
- ‚úÖ Lockfile `uv.lock` pour reproductibilit√©

### 8. **Version control**
- ‚úÖ `.gitignore` adapt√© (donn√©es, logs, venv)
- ‚úÖ Fichiers sensibles exclus (`.env`)
- ‚úÖ Structure de projet propre

---

## üîß D√©pannage

### Probl√®me : Erreur de connexion PostgreSQL

```bash
# V√©rifier que PostgreSQL est lanc√©
docker compose ps

# Tester la connexion manuellement
psql -h localhost -U postgres -d workshop
```

### Probl√®me : T√©l√©chargement √©choue (403)

Certains mois peuvent ne pas √™tre disponibles sur AWS. Le script log les erreurs et continue.

### Probl√®me : Table d√©j√† existante

Les tables sont automatiquement recr√©√©es (DROP IF EXISTS) pour √©viter les conflits.

### Probl√®me : Logs trop verbeux

Modifiez le niveau de log dans `logger.py` :

```python
logger = configure_logging(
    log_file="download.log",
    log_level=logging.WARNING  # Au lieu de INFO
)
```

---

## üìö Ressources

### Documentation Python
- [Polars Documentation](https://pola-rs.github.io/polars-book/) - DataFrame rapide
- [psycopg2 Guide](https://www.psycopg.org/docs/) - PostgreSQL pour Python
- [SQLAlchemy Docs](https://docs.sqlalchemy.org/) - ORM et connexions DB
- [python-dotenv](https://pypi.org/project/python-dotenv/) - Gestion des .env

### Outils
- [uv Package Manager](https://github.com/astral-sh/uv) - Gestionnaire Python moderne
- [Docker PostgreSQL](https://hub.docker.com/_/postgres) - Image officielle

### Dataset
- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) - Donn√©es officielles
- [Data Dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf) - Description des colonnes

---

## üë§ Auteur

**Abraham KOLOBOE** - *Data Engineer & Formateur*

- GitHub: [@abrahamkoloboe27](https://github.com/abrahamkoloboe27)
- LinkedIn: [Abraham KOLOBOE](https://www.linkedin.com/in/abraham-zacharie-koloboe-data-science-ia-generative-llms-machine-learning/)
- Organisation: [IFRI Future of AI](https://github.com/IFRI-Future-of-AI)

---

## üìú Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](../LICENSE) pour plus de d√©tails.

---

## ü§ù Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. Cr√©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Pushez sur la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

---

<div align="center">
  
**Cr√©√© dans le cadre du Data Engineering Workshop - IFRI Future of AI** üéì

[‚¨Ü Retour au Projet Principal](../README.md)

</div>
